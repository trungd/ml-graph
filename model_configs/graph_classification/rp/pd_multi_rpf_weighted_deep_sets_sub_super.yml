backend: pytorch
random_seed: 1
env:
  default:
    variables:
      batch_size: 256
      dropout: 0.2
      learning_rate: 0.01
      early_stop: 50
      num_encoder_layers: 4
      encoder_dim: 64
      decoder_dim: 64
      num_decoder_layers: 4
      combine_encoder: weight_pooling
      num_epochs: 500
      batch_norm: false
      multi_encoder: false
      quantize_type: none
      quantize_size: 100
      append_embedding_to_encoder_output: true
  mutag:
    default: false
    variables:
      dataset: MUTAG
      feature_name:
        - multi_1.2.3.4.5.6.7.8
      signature: [rpf]
      encoder_dim: 8, 8
      decoder_dim: 8, 8
      num_epochs: 100
  nci:
    default: false
    variables:
      dataset:
        - NCI1
        #- NCI109
      feature_name:
        - freq_multi_1.2.3.4.5.6.7.8
        - freq_multi_1.2.3.4
        - freq_multi_1.3.5.7
        #- freq_multi_1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16
        #- freq_multi_1.3.5.7.9.11.13.15
      encoder_dim: 64, 128
      decoder_dim: 128, 64, 32, 16
      hidden_dim: 128
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      batch_size: 256
      num_epochs: 200
      multi_encoder: true
  dd:
    default: false
    variables:
      dataset: DD
      feature_name:
        - multi_1.2.3.4.5.6.7.8
      hidden_dim: [32, 64]
      signature: [rpf, rpf_lbl]
      num_epochs: 200
  proteins:
    default: false
    variables:
      dataset: PROTEINS
      feature_name:
        - freq_multi_1
        - freq_multi_1.2.3.4.5.6.7.8
        - freq_multi_1.2.3.4
        - freq_multi_1.3.5.7
      num_encoder_layers: 2
      num_decoder_layers: 4
      hidden_dim: [64, 128]
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      batch_size: 256
      num_epochs: 200
      multi_encoder: true
  enzymes:
    default: false
    variables:
      dataset: [ENZYMES]
      feature_name:
        - multi_1.2.3.4.5.6.7.8
      hidden_dim: [32, 64]
      batch_size: 768
      signature: [rpf, rpf_lbl]
      num_epochs: 200
  ptc:
    default: false
    variables:
      dataset:
        - PTC_MR
        - PTC_FR
        - PTC_MM
        - PTC_FM
      feature_name:
        #- multi_1
        - multi_1.2.3.4.5.6.7.8
      hidden_dim: [32, 64]
      batch_size: 512
      dropout: [0.0, 0.5]
      batch_norm: true
      signature: [rpf, rpf_lbl]
      learning_rate: 0.01
      num_encoder_layers: 2
      num_decoder_layers: 2
      num_epochs: 200
  reddit:
    default: false
    variables:
      dataset:
        - REDDIT-BINARY
      feature_name:
        #- freq_multi_1
        #- freq_multi_1.2.3.4
        #- freq_multi_1.3.5.7
        - freq_multi_1.2.3.4.5.6.7.8
        #- embed_rpf_2.4.6.8
        #- embed_rpf_4.8.12.16
        #- embed_rpf_2.4.6
        #- embed_rpf_3.6.9
      num_encoder_layers: 2
      num_decoder_layers: 4
      hidden_dim: [64, 128]
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      batch_size: 128
      num_epochs: 200
      multi_encoder: true
  reddit5k:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        - freq_multi_1.2.3.4
        #- freq_multi_1.2.3.4.5.6.7.8
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      encoder_dim: 128, 128
      decoder_dim: 128, 128, 128
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 128
      multi_encoder: true
      combine_encoder: weight_pooling
      quantize_type: none
      append_embedding_to_encoder_output: true
  reddit5k_1:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        #- freq_multi_1.2.3.4
        - freq_multi_1.2.3.4.5.6.7.8
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      num_encoder_layers: 2
      num_decoder_layers: 4
      encoder_dim: 128
      decoder_dim: 128
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 50
      multi_encoder: true
      combine_encoder: weight_pooling
      quantize_type: none
      append_embedding_to_encoder_output: false
  reddit5k_2:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        #- freq_multi_1.2.3.4
        - freq_multi_1.2.3.4
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      encoder_dim: 128, 128
      decoder_dim: 128, 128, 128
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 64
      multi_encoder: true
      combine_encoder: pooling
      quantize_type: none
      append_embedding_to_encoder_output: true
  reddit5k_3:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        #- freq_multi_1.2.3.4
        - freq_multi_1.2.3.4
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      num_encoder_layers: 2
      num_decoder_layers: 4
      encoder_dim: 128
      decoder_dim: 128
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 64
      multi_encoder: false
      combine_encoder: weight_pooling
      quantize_type: none
      append_embedding_to_encoder_output: true
  reddit5k_4:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        #- freq_multi_1.2.3.4
        - freq_multi_1.2.3.4
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      num_encoder_layers: 2
      num_decoder_layers: 4
      encoder_dim: 32
      decoder_dim: 128
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 64
      multi_encoder: true
      combine_encoder: concat
      quantize_type: none
      append_embedding_to_encoder_output: true
  reddit5k_5:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        #- freq_multi_1.2.3.4
        - freq_multi_1.2.3.4
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      num_encoder_layers: 2
      num_decoder_layers: 4
      encoder_dim: 32
      decoder_dim: 128
      dropout: 0.5
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 64
      multi_encoder: true
      combine_encoder: pooling
      quantize_type: none
      append_embedding_to_encoder_output: true
  reddit5k_6:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        #- freq_multi_1.2.3.4
        - freq_multi_1.5.9.13
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      num_encoder_layers: 2
      num_decoder_layers: 4
      encoder_dim: 32
      decoder_dim: 128
      dropout: 0.5
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 64
      multi_encoder: true
      combine_encoder: concat
      quantize_type: none
      append_embedding_to_encoder_output: true
  reddit5k_7:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        #- freq_multi_1.2.3.4
        - freq_multi_1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      encoder_dim: 64, 128
      decoder_dim: 128, 64, 32, 16
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 32
      multi_encoder: true
      combine_encoder: weight_pooling
      quantize_type: none
      append_embedding_to_encoder_output: true
  reddit5k_8:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        #- freq_multi_1.2.3.4
        - freq_multi_1.2.3.4.5.6.7.8
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      encoder_dim: 64, 128
      decoder_dim: 128, 64, 32, 16
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 64
      multi_encoder: true
      combine_encoder: weight_pooling
      quantize_type: none
      append_embedding_to_encoder_output: true
  reddit5k_9:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        - freq_multi_1.2.3.4
        #- freq_multi_1.2.3.4.5.6.7.8
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      encoder_dim: 16, 32, 64, 128
      decoder_dim: 128, 64, 32, 16
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 128
      multi_encoder: true
      combine_encoder: weight_pooling
      quantize_type: none
      append_embedding_to_encoder_output: true
  reddit5k_10:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        - freq_multi_1.2.3.4
        #- freq_multi_1.2.3.4.5.6.7.8
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      encoder_dim: 32, 64, 128, 256
      decoder_dim: 256, 128, 64, 32
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 128
      multi_encoder: false
      combine_encoder: weight_pooling
      quantize_type: none
      append_embedding_to_encoder_output: true
  reddit12k:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-12K
      feature_name:
        #- freq_multi_1
        #- freq_multi_1.2.3.4.5.6.7.8
        - freq_multi_1.2.3.4
        #- freq_multi_1.3.5.7
      num_encoder_layers: 2
      num_decoder_layers: 4
      hidden_dim: 128
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      batch_size: 64
      num_epochs: 200
      multi_encoder: false
      quantize_type: none
      quantize_size: 100
  reddit5k_11:
    default: false
    variables:
      dataset:
        - REDDIT-MULTI-5K
      feature_name:
        #- freq_multi_1
        - freq_multi_1.2.3.4
        #- freq_multi_1.2.3.4.5.6.7.8
        #- freq_multi_1.3.5.7
        #- freq_multi_1.3.5.7.9.11.13.15
      encoder_dim: 64, 128
      decoder_dim: 128, 64, 32, 16
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      num_epochs: 120
      batch_size: 256
      multi_encoder: false
      combine_encoder: weight_pooling
      quantize_type: none
      append_embedding_to_encoder_output: true
  imdb:
    default: false
    variables:
      dataset:
        - IMDB-BINARY
        - IMDB-MULTI
      feature_name:
        - freq_multi_1
        - freq_multi_1.2.3.4
        - freq_multi_1.2.3.4.5.6.7.8
      num_encoder_layers: 2
      num_decoder_layers: 4
      hidden_dim: [64, 128]
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      batch_size: 256
      num_epochs: 200
      multi_encoder: true
  collab:
    default: false
    variables:
      dataset:
        - COLLAB
      feature_name:
        #- multi_1.2.3.4.5.6.7.8
        - freq_multi_1
        #- freq_multi_1.2.3.4
        - freq_multi_1.2.3.4.5.6.7.8
      num_encoder_layers: 2
      num_decoder_layers: 4
      hidden_dim: [128]
      dropout: 0.2
      signature: rpf
      learning_rate: 0.01
      batch_size: 128
      num_epochs: 200
      multi_encoder: true
  cox2_dhfr:
    default: false
    variables:
      dataset: [COX2, DHFR]
      feature_name:
        - multi_1.2.3.4.5.6.7.8
      signature: [rpf, rpf_lbl]
      hidden_dim: 32
      num_epochs: 500
      batch_size: 728
      batch_norm: true
      num_encoder_layers: 2
      num_decoder_layers: 2
      # dropout: 0.2
  frank:
    default: false
    variables:
      dataset:
        - FRANKENSTEIN
      feature_name:
        - embed_rpf_1
        - embed_rpf_2.4.6.8
        - embed_rpf_1.3.5.7
        - embed_rpf_1.2.3.4.5.6.7.8
      hidden_dim: 32
      dense_dim: 32
      signature: [rpf]
    report:
      type: raw
      reduce: []
  synthetic:
    default: false
    variables:
      dataset:
        - SYNTHETIC
      feature_name:
        - embed_rpf_1
        - embed_rpf_2.4.6.8
        - embed_rpf_1.3.5.7
        - embed_rpf_1.2.3.4.5.6.7.8
      hidden_dim: 64
      dense_dim: 64
      signature: [rpf, rpf_lbl]
model:
  name: src.models.set_transformer.MultiWeightedDeepSets
  num_encoder_layers: ~num_encoder_layers
  num_decoder_layers: ~num_decoder_layers
  encoder_dim: ~encoder_dim
  decoder_dim: ~decoder_dim
  dense_dim: ~hidden_dim
  dropout: ~dropout
  batch_norm: ~batch_norm
  multi_encoder: ~multi_encoder
  combine_encoder: ~combine_encoder
  relu_before_pooling: false
  feature_element_weights: false
  weight_activation: softmax
  append_embedding_to_encoder_output: ~append_embedding_to_encoder_output
dataset:
  name: src.datasets.grakel.Grakel
  dataset_name: ~dataset
  graph_features:
    persistence_diagram:
      type: persistence_diagram
      key: ~feature_name
      filtration: vertex_weight_sub_super
      signature: ~signature
      max_length: 10000
      quantize:
        type: ~quantize_type
        size: ~quantize_size
  reuse: false
  test_size: 0.1
train:
  num_epochs: ~num_epochs
  # early_stop:
  #   num_epochs: 50
  batch_size: ~batch_size
  optimizer:
    name: adam
    lr: ~learning_rate
  lr_scheduler:
    # milestones: [15, 30, 45, 60]
    # milestones: [25, 50, 75, 100, 125, 150]
    milestones: [15, 30, 45, 60, 75, 90]
    gamma: 0.5
  cross_validation: 10
  select_model: last
  save_every: 1000e
test:
  metrics: [acc]